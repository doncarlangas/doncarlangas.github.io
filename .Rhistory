depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
?mdy
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
bye()
set.seed(1)
?rpois
rpois(5,2)
rpois(5,2)
set.seed(1)
rpois(5,2)
?rnorm
?set.seed
?rpois
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
t
y
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
?rnorm
?rbinom
x
ss06hid <- read.csv("F:/Coursera/Data Science/GettingandCleaningData/Quiz 4/getdata-data-ss06hid.csv", stringsAsFactors=FALSE)
View(ss06hid)
n <- names(ss06hid)
?strsplit
a <- strsplit(n, "wgtp")
a
a[123]
GDP <- read.csv("F:/Coursera/Data Science/GettingandCleaningData/Quiz 4/getdata-data-GDP.csv", stringsAsFactors=FALSE)
View(GDP)
?gsub
gsub(",","",GDP$US.dollars.)
gsub(",","",GDP$US.dollars.) %>% gsub(" ","")
gsub(" ","",gsub(",","",GDP$US.dollars.)
)
mean(as.numeric(gsub(" ","",gsub(",","",GDP$US.dollars.)))
)
?grep
grep("United$", GDP$Economy)
grep("^United", GDP$Economy)
GDP[grep("^United", GDP$Economy), "Economy"]
GDP[grep("*United", GDP$Economy), "Economy"]
?LM
?lm
ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
weight <- c(ctl, trt)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
Rprof()
Rprof()
fit <- lm(weight ~ group)
Rprof(NULL)
?Rprof
Rprof(NULL)
Rprof("carlos.out")
fit <- lm(weight ~ group)
Rprof(NULL)
fit <- lm(weight ~ group)
Rprof(NULL)
asdasd
Rprof(NULL)
bye
asd
Rprof("carlos.out")
fit <- lm(weight ~ group)
Rprof(NULL)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
print(p)
?trellis.par.set
source('~/.active-rstudio-document')
qplot(Wind, Ozone, data = airquality)
library(ggplot2)
library(ggplot)
install.packages("ggplot2")
library(ggplot2)
ls
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality, facets = . ~ Month, geom= "smooth")
source('~/.active-rstudio-document')
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth("loess"))
qplot(votes, rating, data = movies, smooth="loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
library(swirl)
install_from_swirl("Statistical Inference")
?pnorm
pnorm(70,mean = 80, sd = 10)
qnorm(.95, mean = 1100,sd = 75)
qnorm(.95, mean = 1100,sd = 75/10)
choose(5,4)
choose(5,5)
choose(5,4)*.5^4*.5^1 + choose(5,5)*.5^5
pnorm(14,mean = 15, sd = 1)
pnorm(16,mean = 15, sd = 1) - pnorm(14,mean=15, sd = 1)
?ppois
ppois(10,15)
?knitr::kable
c('1','1')
?rexp
mean(rexp(40,.2))
1/.2
mean(rexp(40,.2))
mean(rexp(40,.2))
mean(rexp(40,.2))
mean(rexp(40,.2))
mean(rexp(40,.2))
mean(rexp(40,.2))
mean(rexp(40,.2))
mean(rexp(40,.2))
mean(rexp(40,.2))
mean(rexp(40,.2))
mean(rexp(40,.2))
hist(rexp(40,2))
?matrix
matrix(rexp(40,2),4,10)
?apply
apply(matrix(rexp(40,2),4,10),mean,1)
apply(matrix(rexp(40,2),4,10),1,mean)
apply(matrix(rexp(40,2),10,4),1,mean)
mean(apply(matrix(rexp(40,2),10,4),1,mean))
mean(apply(matrix(rexp(40,.2),10,4),1,mean))
summary(ToothGrowth)
View(ToothGrowth)
library(ggplot2)
ggplot(ToothGrowth, aes(x=supp, y=len)) + geom_boxplot()
ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_boxplot()
ggplot(ToothGrowth, aes(x=as.factor(dose), y=len)) + geom_boxplot()
p2 <- ggplot(ToothGrowth, aes(x=as.factor(dose), y=len)) + geom_boxplot()
p1 <- ggplot(ToothGrowth, aes(x=dose, y=len)) + geom_boxplot()
multiplot(p1,p2)
?t.test
t.test(ToothGrowth$len[ToothGrowth$supp=="OJ"],ToothGrowth$len[ToothGrowth$supp=="VC"], paired = FALSE, var.equal = TRUE)
a <- t.test(ToothGrowth$len[ToothGrowth$supp=="OJ"],ToothGrowth$len[ToothGrowth$supp=="VC"], paired = FALSE, var.equal = TRUE)
names(a)
t.test(ToothGrowth$len[as.factor(ToothGrowth$dose)=="0.5"],ToothGrowth$len[as.factor(ToothGrowth$dose)=="1.0"], paired = FALSE, var.equal = TRUE)
as.factor(ToothGrowth$dose)=="0.5"
as.factor(ToothGrowth$dose)=="1.0"
as.factor(ToothGrowth$dose)=="1"
t.test(ToothGrowth$len[as.factor(ToothGrowth$dose)=="0.5"],ToothGrowth$len[as.factor(ToothGrowth$dose)=="1"], paired = FALSE, var.equal = TRUE)
?p.test
?t.test
baseline <- c(140,138,150,148,135)
week2 <- c(132,135,151,146,130)
t.test(baseline,week2, paired = TRUE, var.equal = TRUE)
?tprob
?qt
qt(0.975,8)
qt(0.025,8)
1100 + (30/9)*qt(0.975,8)
1100 + (30/sqrt(9))*qt(0.975,8)
1100 + (30/sqrt(9))*qt(0.025,8)
pt(0.75,3)
pt(0.75,3)
pt(1,3)
?power.t.test
power.t.test(n=100, delta = -0.01, sd = 0.04, sig.level = 0.05, alternative = "one.sided")
power.t.test(n=100, delta = 0.01, sd = 0.04, sig.level = 0.05, alternative = "one.sided")
power.t.test(n=100, delta = 0.01, sd = 0.04, sig.level = 0.05, alternative = "one.sided", type = "one.sample")
power.t.test(power = 0.9, delta = 0.01, sd = 0.04, sig.level = 0.05, alternative = "one.sided", type = "one.sample")
power.t.test(power = 0.9, delta = 0.01, sd = 0.04, sig.level = 0.10, alternative = "one.sided", type = "one.sample")
power.t.test(n=100, delta = 0.01, sd = 0.04, sig.level = 0.10, alternative = "one.sided", type = "one.sample")
t.test?
?
qwe
?t.test
sp = sqrt((1.5^2 + 1.8^2)/2)
t <- (-3 - 1)/(sp*(sqrt(2/9))
)
?tp
?pt
pt(t,16)
sd(c(1,1,1,0))
(.75-0.5)/(0.5/sqrt(4))
?pt
pt(1,3)
pt(1,4)
pt(1,3)
?t.test
t.test(c(1,1,1,0), alternative = "greater", mu = 0.25)
t.test(c(1,1,1,0), alternative = "greater", mu = -0.25)
t.test(c(1,1,1,0), alternative = "less", mu = 0.25)
t.test(c(1,1,1,0), alternative = "less", mu = -0.25)
choose(4,3)
choose(4,3)*.5^4 + choose(4,4)*.5^4
?pbinom
pbinom(3,4,0.5)
pbinom(.75,4,0.5)
pbinom(.75,4,0.5, lower.tail = FALSE)
pbinom(2,4,0.5)
pbinom(2,4,0.5, lower.tail = FALSE)
?ppois
10/1787
100*10/1787
a <- 100*10/1787
ppois(a,1)
ppois(a,1,lower.tail= FALSE)
A <- 15800/30
?ppois(A,520)
ppois(A,520)
ppois(A,520, lower.tail = FALSE)
ppois(15800,520*30, lower.tail = FALSE)
ppois(10,1*17.87, lower.tail = FALSE)
ppois(10,1*17.87, lower.tail = true)
ppois(10,1*17.87, lower.tail = TRUE)
?rexp
?matrix
?rexp
?matrix
a <- matrix(rexp(40000,0.2),ncol = 40, nrow = 1000)
?apply
s <- apply(a,2,sd)
s <- apply(a,2,1)
s <- apply(a,1,sd)
hist(s)
a <- matrix(rexp(400000,0.2),ncol = 40, nrow = 10000)
s <- apply(a,1,sd)
hist(s)
?sample
votes <- sample(c(0,1),2500,replace = TRUE, prob = c(0.7,0.3))
sum(votes)
avg(votes)
mean(votes)
?matrix
nrow <- 1000
ncols <- 2500
nrow <- 10000
ncol <- 2500
b <- matrix(sample(votes,ncol*nrow,replace = TRUE),nrow,ncol)
m <- apply(b,1,mean)
hist(m)
p <- 0.3
votes <- sample(c(0,1),2500,replace = TRUE, prob = c(1-p,p))
ap <- mean(votes)
nrow <- 10000
ncol <- 2500
b <- matrix(sample(votes,ncol*nrow,replace = TRUE),nrow,ncol)
m <- apply(b,1,mean)
hist(m)
p <- 0.3
votes <- sample(c(0,1),2500,replace = TRUE, prob = c(1-p,p))
ap <- mean(votes)
nrow <- 10000
ncol <- 2500
b <- matrix(sample(votes,ncol*nrow,replace = TRUE),nrow,ncol)
m <- apply(b,1,mean)
hist(m)
p <- 0.3
votes <- sample(c(0,1),2500,replace = TRUE, prob = c(1-p,p))
ap <- mean(votes)
nrow <- 10000
ncol <- 2500
b <- matrix(sample(votes,ncol*nrow,replace = TRUE),nrow,ncol)
m <- apply(b,1,mean)
hist(m)
p <- 0.3
votes <- sample(c(0,1),2500,replace = TRUE, prob = c(1-p,p))
ap <- mean(votes)
nrow <- 10000
ncol <- 2500
b <- matrix(sample(votes,ncol*nrow,replace = TRUE),nrow,ncol)
m <- apply(b,1,mean)
hist(m)
ap
p <- 0.3
votes <- sample(c(0,1),2500,replace = TRUE, prob = c(1-p,p))
ap <- mean(votes)
nrow <- 10000
ncol <- 2500
b <- matrix(sample(votes,ncol*nrow,replace = TRUE),nrow,ncol)
m <- apply(b,1,mean)
hist(m)
ap
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
install.packages("caret")
library(caret)
data(AlzheimerDisease)
View(diagnosis)
View(predictors)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
head(trainIndex)
length(trainIndex)
length(diagnosis)
rm(list=ls())
data(concrete)
head(mixtures$CompressiveStrength)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(concrete)
library(ggplot2)
concrete$index
p1 <- qplot(concrete$CompressiveStrength,inTrain) + geom_point()
p1
p1 <- qplot(training$CompressiveStrength,inTrain) + geom_point()
p1
p1 <- qplot(inTrain,training$CompressiveStrength) + geom_point()
p1
library(Hmisc)
?cut2
p1 <- qplot(inTrain,training$CompressiveStrength, colour = cut2(inTrain$Age),3) + geom_point()
p1
p1 <- qplot(inTrain,training$CompressiveStrength, colour = cut2(training$Age),3) + geom_point()
p1
p1 <- qplot(inTrain,training$CompressiveStrength, colour = cut2(training$FlyAsh),3) + geom_point()
p1
qplot(inTrain,cut2(training$CompressiveStrength,4), colour = cut2(training$FlyAsh),3) + geom_point()
qplot(inTrain,training$CompressiveStrength, colour = cut2(training$FlyAsh),3) + geom_point()
rm(list=ls())
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(training$Superplasticizer) + geom_hist()
qplot(training$Superplasticizer)
qplot(log(training$Superplasticizer+1))
rm(list=ls())
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(predictors)
sub(names(predictors),2) == "IL"
?sub
grep("^IL", names(predictors))
?preProcess
a <- preProcess(train[,grep("^IL", names(predictors))],method = "pca", tresh = 0.9)
a <- preProcess(training[,grep("^IL", names(predictors))],method = "pca", tresh = 0.9)
a <- preProcess(training[,grep("^IL", names(predictors))],method = "pca", thresh = 0.9)
rm(list=ls())
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(predictors)
names(diagnosis)
head(names(adData))
train <- training[,c(1,grep("^IL", names(training)))]
names(train)
a <- preProcess(training[,grep("^IL", names(training))],method = "pca", tresh = 0.9)
a <- preProcess(training[,grep("^IL", names(training))],method = "pca", thresh = 0.9)
?train
trainS <- training[,c(1,grep("^IL", names(training)))]
a <- train(diagnosis ~ ., data = trainS, method = "glm")
a <- train(trainS[,-1], trainS[,1], method = "glm")
install.packages('e1071', dependencies=TRUE)
a <- train(trainS[,-1], trainS[,1], method = "glm")
b <- predit.train(a, testing[,grep("^IL",names(testing))])
b <- predict.train(a, testing[,grep("^IL",names(testing))])
b <- predict(a, testing[,grep("^IL",names(testing))])
b <- predict(a, testing[,c(1,grep("^IL",names(testing)))])
rm=(list=ls())
rm(list=ls())
clc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[,c(1,grep("^IL"), names(training))]
training <- training[,c(1,grep("^IL",names(training)))]
testing <- testing[,c(1,grep("^IL",names(testing)))]
a <- train(diagnosis~.,data = training, method = "glm")
b <- predict(a, newdata = testing)
b
confusionMatrix(data = b, testing$diagnosis)
?train
?preProcess
a <- train(diagnosis~.,data = training, method = "glm", preProcess = "PCA")
a <- train(diagnosis~.,data = training, method = "glm", preProcess = "pca")
b <- predict(a, newdata = testing)
confusionMatrix(data = b, testing$diagnosis)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)
data(mtcars)
mtcars
fit <- lm( mpg ~ weight, data = mtcars)
names(mtcars)
fit <- lm( mpg ~ wt, data = mtcars)
summary(fit)
predict(fit, mean(mtcars$wt) , interval="confidence")
predict(fit, as.dataframe(mean(mtcars$wt)) , interval="confidence")
predict(fit, as.data.frame(mean(mtcars$wt)) , interval="confidence")
mtcars$wt
predict(fit, newdata = data.frame(wt=mean(mtcars$wt)) , interval="confidence")
?mtcars
View(mtcars)
predict(fit, newdata = data.frame(wt=3 , interval="confidence")
asd
predict(fit, newdata = data.frame(wt=3) , interval="confidence")
fit <- lm( mpg ~ I(wt*1000), data = mtcars)
summary(fit)
predict(fit, newdata = data.frame(wt=3000) , interval="confidence")
predict(fit, newdata = data.frame(wt=3) , interval="confidence")
predict(fit, newdata = data.frame(wt=3) , interval="predict")
confint(fit, level = 0.95)
fit <- lm( mpg ~ wt, data = mtcars)
summary(fit)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='doncarlangas', token='A589D368162BD1FBFB8E2DE56398BBC1', secret='VCYAmmSP33cfOq0jmSNbByZ+f3lTOzZ9YLqNFYJ5')
library(shinyapps)
shinyapps::deployApp('F:./././Coursera/Data Science//Developing Data Products//Course Project')
shinyapps::deployApp('F:./././Coursera/Data Science//Developing Data Products//Course Project//')
shinyapps::deployApp('F://Coursera/Data Science//Developing Data Products//Course Project')
shinyapps::deployApp(appName="Coursera",'F://Coursera/Data Science//Developing Data Products//Course Project')
fit <- lm(qsec ~ hp + wt, data=mtcars)
newdata = data.frame(hp = 110, wt = 2.620)
predict(fit,newdata)
newdata = data.frame(hp = 160, wt = 2.620)
predict(fit,newdata)
newdata = data.frame(hp = 250, wt = 2.620)
predict(fit,newdata)
getwd()
setwd("F:\Coursera/Data Science/Developing Data Products/Course Project/")
setwd("F:/Coursera/Data ScienceDeveloping Data Products/Course Project/")
setwd("F://Coursera/Data Science//Developing Data Products//Course Project")
runapp()
library(shiny)
runapp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shinyapps::deployApp(appName="DataProducts",'F://Coursera/Data Science//Developing Data Products//Course Project')
shinyapps::deployApp(appName="DataProducts",'F://Coursera/Data Science//Developing Data Products//Course Project')
shiny::runApp()
shiny::runApp()
shiny::runApp()
shinyapps::deployApp(appName="DataProducts",'F://Coursera/Data Science//Developing Data Products//Course Project')
shinyapps::deployApp(appName="DataProducts",'F://Coursera/Data Science//Developing Data Products//Course Project')
shinyapps::deployApp(appName="DataProducts",'F://Coursera/Data Science//Developing Data Products//Course Project')
library(slidify)
require(devtools)
install_github("slidify", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
library(slidify)
author("doncarlangas")
slidify("index.Rmd")
slidify("index.Rmd")
fit
summary(lm)
summary(fit)
fit
fit$coeffcients
fit$coefficients
publish(title = 'DevelopingDataProducts', 'index.html', host = 'rpubs')
publish(title = 'DevelopingDataProducts', 'index.html', host = 'rpubs')
publish(title = 'DevelopingDataProducts', 'index.html', host = 'rpubs')
publish(title = 'DevelopingDataProducts', 'index.html', host = 'rpubs')
